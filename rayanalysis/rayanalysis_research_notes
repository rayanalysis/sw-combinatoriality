The "sperm-whale-dialogues.csv" appears to be the closest data source to ground truth, that is to say the data is apparently raw. It consists firstly of the "REC" column which is the "audio file name" IE "sw061b001_124" of the raw whale audio files, presumably, which were not included in the source distribution. These file names may have multiple rows of the same file name column values, showing the specific whale-clicking events but not in temporal order.

Each "REC" file consists of an "nClicks" column showing the total number of clicks during that (part of the) recording. The next column "Duration" does not have the units labeled, but it is presumably seconds. The next column is "ICI1" which goes till "ICI28" columnwise which are floats and ints like "0.2989993" and "0" until we reach "Whale" (an integer, 1 through ~20), and "TsTo" which is currently an unknown, a float value like "16281.7994" or "47.2508", but presumably "TsTo" is the "start time" of the whale sound, which might be used to logically cluster the whales having a "conversation" on a timeline.

"ICI" means "inter click intervals". My working theory is that the ICI1 through ICI28 columns are the sub-durations of the whale sounds which effectively add up to the total duration (this can be checked by summing the ICI durations and ensuring they're never more than the total duration). The "modulation" of these float values may yield most of the "linguistic" information coming from the whale's various expressions.

(personal note) I would prefer the data to be labeled and structured in roughly the following manner: 1. Provide the raw audio files 2. Specify audio characteristics such as the decibel level and hertz frequency over time in the datasets 3. Provide clear time-dimension, location-dimension data by default, instead of expecting potential collaborators to carefully inspect source to make guesses about basic data groupings. This project could be both simplified and expanded simultaneously by removing the great deal of assumptions made about the whale expression (probably included in an attempt to build on previous research) as a matter of first priority. Then, we can elaborate this new totally clear evidentiary basis which makes zero assumptions about the interactive dynamics or fundamental structure of whale expression. The proliferation of abstract identifiers IE "Tempo", "Rhythm", "Ornamentation", "Rubato", and "coda" in the analysis come across as fairly presumptive, particularly without the aforementioned evidentiary basis already clearly defined, and also without some production of meaning from the whale expressions data using that conceptual framework. I'd rather not overdescribe the phenomenology before we have more straightforwardly examined the data.

(8/9/24) I have written the first "main.py" program in the "rayanalysis" subfolder of the forked sw-combinatoriality source repo, which does the following: 1. Takes the "sperm-whale-dialogues.csv" data file and splits it procedurally into ~200 individual recording data files, grouped by the REC filename. This data should now be more dimensionally and temporally clear for first-principles study.

(8/9/24 cont) I have written the initial plotting logic in "run_plots.py" to illustrate the whale expression data across the time dimension given specific audio recordings and their whale expressions based on the "Whale" number. Figure 1 is provided in the /rayanalysis subfolder as a .png image.
